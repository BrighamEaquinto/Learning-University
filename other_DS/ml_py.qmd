---
title: "Regression Model"
format: html
eval: false
---


### Libraries
```{python}
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn import tree

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.pipeline import make_pipeline

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

import seaborn as sns
```

### Data & Preprocessing
```{python}
dat = pd.read_csv("https://raw.githubusercontent.com/saundersg/Statistics-Notebook/master/Data/CarPrices.csv")

dat = pd.get_dummies(dat)
```

### Splitting
```{python}
y = dat.filter(['Price'], axis = 1)
X = dat.drop('Price', axis = 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```


### Modeling
```{python}
model = tree.DecisionTreeRegressor()
model = model.fit(X_train, y_train)
y_pred1 = model.predict(X_test)
```

```{python}
make_pipeline(StandardScaler(), GaussianNB(priors=None))
```



### Metrics
```{python}
r2 = r2_score(y_test, y_pred1).round(3)
mae = mean_absolute_error(y_test, y_pred1).round(3)
mse = mean_squared_error(y_test, y_pred1, squared=False).round(3)
me = mean_squared_error(y_test, y_pred1, squared=True).round(3)
print(f'R2 = {r2}\nMAE = {mae}\nMSE = {mse}\nME = {me}')
```

### Feature Examination 
```{python}
features_importances = (
    pd.DataFrame({'Columns': np.array(X.columns),
                  'Features': np.array(model.feature_importances_)})
    .sort_values(by = 'Features', ascending = False)
                     )
# features_importances.to_csv("feature_importances.csv")
```

```{python}
sns.barplot(y = 'Columns', x = 'Features', data = features_importances.head(10), color = "lightblue") 
```

<br><br><br>

# Code Graveyard
```{python}
#| include: false
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 314)

X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 314)
```
